{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5db222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import random\n",
    "from EDA_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify dataset filepath \n",
    "\n",
    "# --- original train & test dataset ----\n",
    "filepath_test = '../data/test.csv'\n",
    "df_test = pd.read_csv(filepath_test)\n",
    "filepath_train = '../data/train.csv'\n",
    "# filepath_train = '../data/train_cheat2.csv'\n",
    "df_train = pd.read_csv(filepath_train)\n",
    "\n",
    "# --- auxiliary dataset ----\n",
    "filepath_commercial = '../data/auxiliary-data/sg-commerical-centres.csv'\n",
    "filepath_mrt = '../data/auxiliary-data/sg-mrt-stations.csv'\n",
    "filepath_pri_school = '../data/auxiliary-data/sg-primary-schools.csv'\n",
    "filepath_sec_school = '../data/auxiliary-data/sg-secondary-schools.csv'\n",
    "filepath_mall = '../data/auxiliary-data/sg-shopping-malls.csv'\n",
    "filepath_subzone = '../data/auxiliary-data/sg-subzones.csv'\n",
    "\n",
    "df_commercial = pd.read_csv(filepath_commercial)\n",
    "df_mrt = pd.read_csv(filepath_mrt)\n",
    "df_pri_school = pd.read_csv(filepath_pri_school)\n",
    "df_sec_school = pd.read_csv(filepath_sec_school)\n",
    "df_mall = pd.read_csv(filepath_mall)\n",
    "df_subzone = pd.read_csv(filepath_subzone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723269da",
   "metadata": {},
   "source": [
    "## EDA and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d92067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(eda):\n",
    "    # string value formalization\n",
    "    eda.str_clean_up()\n",
    "    # remove abnormal data\n",
    "    eda.handle_train_abnormal()\n",
    "\n",
    "\n",
    "    # ------ Original Features -------------\n",
    "    # one-hot property type for both train & test\n",
    "    eda.property_type_method()\n",
    "\n",
    "    # processing tenure feature for train data\n",
    "    eda.tenure_method()\n",
    "    # processing tenure feature for test data\n",
    "    eda.tenure_method(for_test=True)\n",
    "\n",
    "    # processing num of beds & baths feature for train data\n",
    "    eda.num_bed_bath_method()\n",
    "    # processing num of beds & baths feature for test data\n",
    "    eda.num_bed_bath_method(for_test=True)\n",
    "\n",
    "    # processing built year feature for train data using method 2\n",
    "    eda.built_year_method2()\n",
    "    # processing built year feature for test data using method 2\n",
    "    eda.built_year_method2(for_test=True)\n",
    "\n",
    "    # one-hot furnishing for both train & test data\n",
    "    eda.furnishing_method()\n",
    "\n",
    "    # one-hot planning area for both train & test data\n",
    "    eda.planning_area_method()\n",
    "\n",
    "\n",
    "    # ------ Auxiliary Features -------------\n",
    "    # calculate shorest distance to different commerical type for train data\n",
    "    eda.cal_min_dis_to_diff_commercial(df_commercial)\n",
    "    # calculate shorest distance to different commerical type for test data\n",
    "    eda.cal_min_dis_to_diff_commercial(df_commercial, for_test=True)\n",
    "\n",
    "    # calculate shorest distance to different MRT lines for train data\n",
    "    eda.cal_min_dis_to_diff_mrt(df_mrt)\n",
    "    # calculate shorest distance to different MRT lines for test data\n",
    "    eda.cal_min_dis_to_diff_mrt(df_mrt, for_test=True)\n",
    "\n",
    "    # calculate shortest distance to primary school for train data\n",
    "    eda.cal_min_dis_to_school_or_mall(df_pri_school, cal_type='pc')\n",
    "    # calculate shortest distance to primary school for test data\n",
    "    eda.cal_min_dis_to_school_or_mall(df_pri_school, cal_type='pc', for_test=True)\n",
    "\n",
    "    # calculate shortest distance to second school for train data\n",
    "    eda.cal_min_dis_to_school_or_mall(df_sec_school, cal_type='sc')\n",
    "    # calculate shortest distance to second school for test data\n",
    "    eda.cal_min_dis_to_school_or_mall(df_sec_school, cal_type='sc', for_test=True)\n",
    "\n",
    "    # calculate shortest distance to shopping mall for train data\n",
    "    eda.cal_min_dis_to_school_or_mall(df_mall, cal_type='sm')\n",
    "    # calculate shortest distance to shopping mall for test data\n",
    "    eda.cal_min_dis_to_school_or_mall(df_mall, cal_type='sm', for_test=True)\n",
    "\n",
    "    # attach with subzone size & population for train data\n",
    "    eda.attach_subzone_auxiliary_info(df_subzone)\n",
    "    # attach with subzone size & population for test data\n",
    "    eda.attach_subzone_auxiliary_info(df_subzone, for_test=True)\n",
    "\n",
    "    # calculate population density for train data\n",
    "    eda.cal_subzone_population_density(df_subzone)\n",
    "    # calculate population density for test data\n",
    "    eda.cal_subzone_population_density(df_subzone, for_test=True)\n",
    "    \n",
    "    \n",
    "    drop_cols = ['listing_id', 'title', 'address', 'property_name', 'floor_level', 'available_unit_types',\n",
    "            'total_num_units', 'property_details_url', 'elevation','subzone', 'planning_area', 'furnishing',\n",
    "            'property_type',]\n",
    "\n",
    "    eda.df.drop(columns=drop_cols, inplace=True)\n",
    "    eda.df_test.drop(columns=drop_cols,inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()\n",
    "\n",
    "eda = EDA(df_train_copy, df_test_copy)\n",
    "setup(eda)\n",
    "\n",
    "df_train_y = eda.df['price']\n",
    "df_train_X = eda.df.drop(columns=['price'])\n",
    "X_train = df_train_X.to_numpy(dtype='float32')\n",
    "y_train = df_train_y.to_numpy(dtype='float32')\n",
    "X_test = eda.df_test.to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b1883",
   "metadata": {},
   "source": [
    "## Max-min Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab16724",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_train.shape[1]):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    col_train = X_train[:, i]\n",
    "    col_train = col_train.reshape(-1, 1)\n",
    "    col_train = min_max_scaler.fit_transform(col_train)\n",
    "    X_train[:, i] = col_train.reshape(-1)\n",
    "    \n",
    "    col_test = X_test[:, i]\n",
    "    col_test = col_test.reshape(-1, 1)\n",
    "    col_test = min_max_scaler.transform(col_test)\n",
    "    X_test[:, i] = col_test.reshape(-1)\n",
    "\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_train = y_train / 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a51e75",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "parameters = {'n_estimators':[20,30,50,80,100,150, 200, 250, 300, 400, 500], \n",
    "              'min_samples_split': [2, 3, 4, 6, 8, 10],\n",
    "              'min_samples_leaf': [2, 3, 4, 6, 8, 10],\n",
    "              'max_features':[1.0, 0.8, 0.6],\n",
    "              'max_depth':[None, 3, 4, 5, 7, 9, 10, 12, 18, 20, 25, 30, 45, 50, 55, 60, 65, 70, 85, 80]\n",
    "\n",
    "             }\n",
    "model = GridSearchCV(estimator=RandomForestRegressor(), param_grid=parameters, verbose=4, cv=5, scoring='neg_root_mean_squared_error')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066af4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = model.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d85b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43f756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fe045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
